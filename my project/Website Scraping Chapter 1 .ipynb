{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting builtwith\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/b8/4a320be83bb3c9c1b3ac3f9469a5d66e02918e20d226aa97a3e86bddd130/builtwith-1.3.3.tar.gz\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.7/site-packages (from builtwith) (1.12.0)\n",
      "Building wheels for collected packages: builtwith\n",
      "  Building wheel for builtwith (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/jacky/Library/Caches/pip/wheels/2b/00/c2/a96241e7fe520e75093898bf926764a924873e0304f10b2524\n",
      "Successfully built builtwith\n",
      "Installing collected packages: builtwith\n",
      "Successfully installed builtwith-1.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install builtwith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtwith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'web-servers': ['Nginx'],\n",
       " 'web-frameworks': ['Web2py', 'Twitter Bootstrap'],\n",
       " 'programming-languages': ['Python'],\n",
       " 'javascript-frameworks': ['jQuery', 'Modernizr', 'jQuery UI']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " builtwith.parse('http://example.webscraping.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-whois in /anaconda3/lib/python3.7/site-packages (0.7.2)\n",
      "Requirement already satisfied: future in /anaconda3/lib/python3.7/site-packages (from python-whois) (0.17.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"domain_name\": [\n",
      "    \"APPSPOT.COM\",\n",
      "    \"appspot.com\"\n",
      "  ],\n",
      "  \"registrar\": \"MarkMonitor, Inc.\",\n",
      "  \"whois_server\": \"whois.markmonitor.com\",\n",
      "  \"referral_url\": null,\n",
      "  \"updated_date\": [\n",
      "    \"2019-02-06 10:33:49\",\n",
      "    \"2019-02-06 02:33:49\"\n",
      "  ],\n",
      "  \"creation_date\": [\n",
      "    \"2005-03-10 02:27:55\",\n",
      "    \"2005-03-09 18:27:55\"\n",
      "  ],\n",
      "  \"expiration_date\": [\n",
      "    \"2020-03-10 01:27:55\",\n",
      "    \"2020-03-09 00:00:00\"\n",
      "  ],\n",
      "  \"name_servers\": [\n",
      "    \"NS1.GOOGLE.COM\",\n",
      "    \"NS2.GOOGLE.COM\",\n",
      "    \"NS3.GOOGLE.COM\",\n",
      "    \"NS4.GOOGLE.COM\",\n",
      "    \"ns3.google.com\",\n",
      "    \"ns2.google.com\",\n",
      "    \"ns1.google.com\",\n",
      "    \"ns4.google.com\"\n",
      "  ],\n",
      "  \"status\": [\n",
      "    \"clientDeleteProhibited https://icann.org/epp#clientDeleteProhibited\",\n",
      "    \"clientTransferProhibited https://icann.org/epp#clientTransferProhibited\",\n",
      "    \"clientUpdateProhibited https://icann.org/epp#clientUpdateProhibited\",\n",
      "    \"serverDeleteProhibited https://icann.org/epp#serverDeleteProhibited\",\n",
      "    \"serverTransferProhibited https://icann.org/epp#serverTransferProhibited\",\n",
      "    \"serverUpdateProhibited https://icann.org/epp#serverUpdateProhibited\",\n",
      "    \"clientUpdateProhibited (https://www.icann.org/epp#clientUpdateProhibited)\",\n",
      "    \"clientTransferProhibited (https://www.icann.org/epp#clientTransferProhibited)\",\n",
      "    \"clientDeleteProhibited (https://www.icann.org/epp#clientDeleteProhibited)\",\n",
      "    \"serverUpdateProhibited (https://www.icann.org/epp#serverUpdateProhibited)\",\n",
      "    \"serverTransferProhibited (https://www.icann.org/epp#serverTransferProhibited)\",\n",
      "    \"serverDeleteProhibited (https://www.icann.org/epp#serverDeleteProhibited)\"\n",
      "  ],\n",
      "  \"emails\": [\n",
      "    \"abusecomplaints@markmonitor.com\",\n",
      "    \"whoisrequest@markmonitor.com\"\n",
      "  ],\n",
      "  \"dnssec\": \"unsigned\",\n",
      "  \"name\": null,\n",
      "  \"org\": \"Google LLC\",\n",
      "  \"address\": null,\n",
      "  \"city\": null,\n",
      "  \"state\": \"CA\",\n",
      "  \"zipcode\": null,\n",
      "  \"country\": \"US\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(whois.whois('appspot.com'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "html= urlopen(\"http://pythonscraping.com/pages/page1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "print(html.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /anaconda3/lib/python3.7/site-packages (4.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /anaconda3/lib/python3.7/site-packages (from beautifulsoup4) (1.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs0bj= BeautifulSoup(html.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = urlopen(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "bsObj = BeautifulSoup(html.read())\n",
    "print(bsObj.h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##確認要爬的網站的html到底可不可行\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html=urlopen(url)\n",
    "    except HTTPError:        ## HTTPError: the url, html or tag \n",
    "            return None      ## have not existed.\n",
    "    try:\n",
    "        bs0bj= BeautifulSoup(html.read())\n",
    "        title= bs0bj.body.h1        ## to confirm that the tag in\n",
    "    except AttributeError:          ## url is readable.\n",
    "        return None                 ## AttributeError: 變量的名稱有錯\n",
    "    return title                    ##或者是程式的格式錯了，code沒錯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "title= getTitle(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "if title== None:\n",
    "   print (\"title could not be found\")\n",
    "else:\n",
    "   print(title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
